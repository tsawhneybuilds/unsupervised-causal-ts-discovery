{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32468e61-d1a5-403a-9d68-bb878cb3966f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rpy2 in /opt/anaconda3/lib/python3.13/site-packages (3.6.4)\n",
      "Requirement already satisfied: rpy2-rinterface>=3.6.3 in /opt/anaconda3/lib/python3.13/site-packages (from rpy2) (3.6.3)\n",
      "Requirement already satisfied: rpy2-robjects>=3.6.3 in /opt/anaconda3/lib/python3.13/site-packages (from rpy2) (3.6.3)\n",
      "Requirement already satisfied: cffi>=1.15.1 in /opt/anaconda3/lib/python3.13/site-packages (from rpy2-rinterface>=3.6.3->rpy2) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.13/site-packages (from cffi>=1.15.1->rpy2-rinterface>=3.6.3->rpy2) (2.21)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from rpy2-robjects>=3.6.3->rpy2) (3.1.6)\n",
      "Requirement already satisfied: tzlocal in /opt/anaconda3/lib/python3.13/site-packages (from rpy2-robjects>=3.6.3->rpy2) (5.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->rpy2-robjects>=3.6.3->rpy2) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "645e1a60-c47e-49a0-a317-2e8aec9dda97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"R_HOME\"] = \"/Library/Frameworks/R.framework/Resources\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7034253f-cc0f-4d1b-8d5e-72da577ba906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_HOME = /Library/Frameworks/R.framework/Resources\n"
     ]
    }
   ],
   "source": [
    "print(\"R_HOME =\", os.environ.get(\"R_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0fce819-6c12-45f7-b4e5-336c083f6197",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from math import log, sqrt\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# If you don't have SciPy, replace this with an approximation\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1. Conditional independence test: Fisher-Z for Gaussian data\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def fisher_z_test(Z, i, j, cond, alpha):\n",
    "    \"\"\"\n",
    "    Gaussian CI test using Fisher-Z.\n",
    "    Z:   data matrix (n_samples, n_nodes)\n",
    "    i,j: indices of variables\n",
    "    cond: iterable of indices (conditioning set)\n",
    "    alpha: significance level\n",
    "    Returns: True if X_i ⟂ X_j | cond  (independent)\n",
    "    \"\"\"\n",
    "    n, p = Z.shape\n",
    "    var_idx = [i, j] + list(cond)\n",
    "    sub = Z[:, var_idx]\n",
    "    C = np.cov(sub, rowvar=False)\n",
    "    # precision\n",
    "    try:\n",
    "        K = np.linalg.inv(C)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # fall back to pseudo-inverse\n",
    "        K = np.linalg.pinv(C)\n",
    "    # partial correlation between first two\n",
    "    r = -K[0, 1] / np.sqrt(K[0, 0] * K[1, 1])\n",
    "    r = max(min(r, 0.999999), -0.999999)\n",
    "    z = 0.5 * log((1 + r) / (1 - r)) * sqrt(max(n - len(cond) - 3, 1))\n",
    "    zcrit = norm.ppf(1 - alpha / 2.0)\n",
    "    return abs(z) <= zcrit\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2. Dynamic PAG graph with homology (SVAR structure)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class NodeInfo:\n",
    "    var: int\n",
    "    lag: int\n",
    "\n",
    "\n",
    "class DynamicPAG:\n",
    "    \"\"\"\n",
    "    Dynamic PAG segment for X_t, ..., X_{t-p}.\n",
    "    Nodes are indexed 0..(k*(p+1)-1).\n",
    "    Each node has (var, lag). lag=0 is time t (most recent).\n",
    "    marks[i,j] is the endpoint mark at j for edge i--j:\n",
    "        0  = circle (o)\n",
    "        -1 = tail   (-)\n",
    "        1  = arrow  (>)\n",
    "    \"\"\"\n",
    "    def __init__(self, var_names, max_lag):\n",
    "        self.var_names = list(var_names)\n",
    "        self.k = len(var_names)\n",
    "        self.p = max_lag\n",
    "        self.n_nodes = self.k * (self.p + 1)\n",
    "\n",
    "        # full complete graph with o-o edges\n",
    "        self.adj = np.ones((self.n_nodes, self.n_nodes), dtype=bool)\n",
    "        np.fill_diagonal(self.adj, False)\n",
    "        self.marks = np.zeros((self.n_nodes, self.n_nodes), dtype=int)\n",
    "\n",
    "        # separation sets: key = (min(i,j), max(i,j)), value = set of nodes\n",
    "        self.sepset = {}\n",
    "\n",
    "    # ----- node indexing / decoding -----\n",
    "\n",
    "    def node_index(self, var, lag):\n",
    "        return lag * self.k + var\n",
    "\n",
    "    def decode_node(self, idx):\n",
    "        lag = idx // self.k\n",
    "        var = idx % self.k\n",
    "        return NodeInfo(var=var, lag=lag)\n",
    "\n",
    "    def node_label(self, idx):\n",
    "        info = self.decode_node(idx)\n",
    "        return f\"{self.var_names[info.var]}_lag{info.lag}\"\n",
    "\n",
    "    # ----- homology: pairs with same var pair + same lag difference -----\n",
    "\n",
    "    def hom_pairs(self, i, j):\n",
    "        info_i = self.decode_node(i)\n",
    "        info_j = self.decode_node(j)\n",
    "        d = info_i.lag - info_j.lag\n",
    "        pairs = []\n",
    "        for a in range(self.p + 1):\n",
    "            b = a - d\n",
    "            if 0 <= b <= self.p:\n",
    "                m = self.node_index(info_i.var, a)\n",
    "                n = self.node_index(info_j.var, b)\n",
    "                pairs.append((m, n))\n",
    "        return pairs\n",
    "\n",
    "    # ----- adjacency restricted by time (adj_t) -----\n",
    "\n",
    "    def neighbors(self, i):\n",
    "        return [j for j in range(self.n_nodes) if self.adj[i, j]]\n",
    "\n",
    "    def adj_t(self, i):\n",
    "        info_i = self.decode_node(i)\n",
    "        res = []\n",
    "        for j in self.neighbors(i):\n",
    "            info_j = self.decode_node(j)\n",
    "            if info_j.lag >= info_i.lag:\n",
    "                res.append(j)\n",
    "        return res\n",
    "\n",
    "    # ----- sepsets -----\n",
    "\n",
    "    def set_sepset(self, i, j, S):\n",
    "        if i > j:\n",
    "            i, j = j, i\n",
    "        self.sepset[(i, j)] = set(S)\n",
    "\n",
    "    def get_sepset(self, i, j):\n",
    "        if i > j:\n",
    "            i, j = j, i\n",
    "        return self.sepset.get((i, j), set())\n",
    "\n",
    "    # ----- edge operations with homology -----\n",
    "\n",
    "    def delete_edge_with_homology(self, i, j):\n",
    "        for m, n in self.hom_pairs(i, j):\n",
    "            if self.adj[m, n]:\n",
    "                self.adj[m, n] = False\n",
    "                self.adj[n, m] = False\n",
    "                self.marks[m, n] = 0\n",
    "                self.marks[n, m] = 0\n",
    "\n",
    "    def _orient_edge(self, i, j, mark_ij, mark_ji):\n",
    "        \"\"\"\n",
    "        Set endpoint marks for edge i-j without touching homology.\n",
    "        mark_ij is mark at j on edge from i to j.\n",
    "        \"\"\"\n",
    "        if not self.adj[i, j]:\n",
    "            return\n",
    "        # simple consistency check: don't overwrite a hard arrow in opposite dir\n",
    "        if self.marks[j, i] == 1 and mark_ij == 1:\n",
    "            # would make i <-> j when there is already arrow at i\n",
    "            pass\n",
    "        self.marks[i, j] = mark_ij\n",
    "        self.marks[j, i] = mark_ji\n",
    "\n",
    "    def orient_with_homology(self, i, j, mark_ij, mark_ji):\n",
    "        \"\"\"\n",
    "        Orient edge (i,j) and all homologous edges with same endpoint pattern.\n",
    "        For example, for i *-> j we pass (1, -1) or (1, 0), etc.\n",
    "        \"\"\"\n",
    "        for m, n in self.hom_pairs(i, j):\n",
    "            if not self.adj[m, n]:\n",
    "                continue\n",
    "            self._orient_edge(m, n, mark_ij, mark_ji)\n",
    "\n",
    "    def reset_all_to_oo(self):\n",
    "        \"\"\"Keep adjacency but set all marks to circle (o-o).\"\"\"\n",
    "        self.marks[:, :] = 0\n",
    "\n",
    "    # ----- helpers for collider / triangle checks -----\n",
    "\n",
    "    def is_collider(self, a, b, c):\n",
    "        \"\"\"\n",
    "        a ?-> b <-? c\n",
    "        \"\"\"\n",
    "        if not (self.adj[a, b] and self.adj[b, c]):\n",
    "            return False\n",
    "        return self.marks[a, b] == 1 and self.marks[c, b] == 1\n",
    "\n",
    "    def forms_triangle(self, a, b, c):\n",
    "        return self.adj[a, b] and self.adj[b, c] and self.adj[a, c]\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 3. Dynamic pds_s (time-restricted possible-d-sep)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def pds_s(graph: DynamicPAG, i, j):\n",
    "    \"\"\"\n",
    "    Time-restricted possible-d-sep set pds_s(X_i, X_j, P).\n",
    "    This is a faithful adaptation of Zhang's pds definition,\n",
    "    restricted to nodes whose lag <= max(lag(i), lag(j)).\n",
    "    \"\"\"\n",
    "    info_i = graph.decode_node(i)\n",
    "    info_j = graph.decode_node(j)\n",
    "    maxlag = max(info_i.lag, info_j.lag)\n",
    "\n",
    "    # BFS over paths satisfying collider-or-triangle condition\n",
    "    result = set()\n",
    "    queue = [[i]]\n",
    "    visited_paths = set()\n",
    "\n",
    "    def path_ok(path):\n",
    "        # all internal triples (a,b,c) must be collider or triangle\n",
    "        if len(path) < 3:\n",
    "            return True\n",
    "        for a, b, c in zip(path[:-2], path[1:-1], path[2:]):\n",
    "            if not (graph.is_collider(a, b, c) or graph.forms_triangle(a, b, c)):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    while queue:\n",
    "        path = queue.pop(0)\n",
    "        last = path[-1]\n",
    "        for nb in graph.neighbors(last):\n",
    "            if nb in path:\n",
    "                continue\n",
    "            new_path = path + [nb]\n",
    "            key = tuple(new_path)\n",
    "            if key in visited_paths:\n",
    "                continue\n",
    "            visited_paths.add(key)\n",
    "            if not path_ok(new_path):\n",
    "                continue\n",
    "\n",
    "            info_nb = graph.decode_node(nb)\n",
    "            if info_nb.lag <= maxlag:\n",
    "                result.add(nb)\n",
    "            queue.append(new_path)\n",
    "\n",
    "    result.discard(i)\n",
    "    result.discard(j)\n",
    "    return result\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 4. SVAR-FCI Algorithm 3.1\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "class SVAR_FCI:\n",
    "    def __init__(self, alpha=0.05, max_lag=2, verbose=False):\n",
    "        self.alpha = alpha\n",
    "        self.max_lag = max_lag\n",
    "        self.verbose = verbose\n",
    "        self.graph_ = None\n",
    "        self.var_names_ = None\n",
    "        self.Z_ = None  # lagged data\n",
    "\n",
    "    # --- lagged data builder (X_t,...,X_{t-p}) ---\n",
    "\n",
    "    def _build_lagged_matrix(self, X, var_names):\n",
    "        \"\"\"\n",
    "        X: np.ndarray (T, k)\n",
    "        Returns Z: (T-p, k*(p+1)), names: list[str]\n",
    "        \"\"\"\n",
    "        T, k = X.shape\n",
    "        p = self.max_lag\n",
    "        rows = T - p\n",
    "        Z = np.zeros((rows, k * (p + 1)))\n",
    "        names = []\n",
    "        for lag in range(p + 1):\n",
    "            Z[:, lag * k:(lag + 1) * k] = X[p - lag:T - lag, :]\n",
    "            for idx, name in enumerate(var_names):\n",
    "                names.append(f\"{name}_lag{lag}\")\n",
    "        return Z, names\n",
    "\n",
    "    # --- independence wrapper ---\n",
    "\n",
    "    def _indep(self, Z, i, j, S):\n",
    "        return fisher_z_test(Z, i, j, S, self.alpha)\n",
    "\n",
    "    # --- skeleton phase (Alg 3.1 lines 3–8) ---\n",
    "\n",
    "    def _skeleton_phase(self, G: DynamicPAG, Z):\n",
    "        if self.verbose:\n",
    "            print(\"Skeleton phase (dynamic adj_t + homology)...\")\n",
    "        n = 0\n",
    "        p = G.n_nodes\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            if self.verbose:\n",
    "                print(f\"  Conditioning set size n={n}\")\n",
    "            for i in range(p):\n",
    "                for j in range(i + 1, p):\n",
    "                    if not G.adj[i, j]:\n",
    "                        continue\n",
    "                    # we test only with Xi as \"left\" node (as in Alg 3.1)\n",
    "                    adj_i_t = [v for v in G.adj_t(i) if v != j]\n",
    "                    if len(adj_i_t) < n:\n",
    "                        continue\n",
    "                    found_sep = False\n",
    "                    for S in itertools.combinations(adj_i_t, n):\n",
    "                        if self._indep(Z, i, j, S):\n",
    "                            if self.verbose:\n",
    "                                print(f\"    indep({G.node_label(i)}, {G.node_label(j)} | {len(S)} vars)\")\n",
    "                            G.delete_edge_with_homology(i, j)\n",
    "                            G.set_sepset(i, j, S)\n",
    "                            changed = True\n",
    "                            found_sep = True\n",
    "                            break\n",
    "                    if found_sep:\n",
    "                        continue\n",
    "            n += 1\n",
    "\n",
    "    # --- line 9: time orientation Xi_t *-> Xj_s if s > t ---\n",
    "\n",
    "    # --- line 9: time orientation Xi_t *-> Xj_s if s > t (past -> future) ---\n",
    "\n",
    "    def _time_orientation(self, G: DynamicPAG):\n",
    "        \"\"\"\n",
    "        Deterministic time-based orientation:\n",
    "\n",
    "        We use lag = 0 for time t (most recent), lag = 1 for t-1, etc.\n",
    "        So a larger lag means an *earlier* time.\n",
    "\n",
    "        The SVAR-FCI rule Xi,t *-> Xj,s iff s > t (later in calendar time)\n",
    "        therefore translates to:\n",
    "\n",
    "            if lag(i) > lag(j):   # i is further in the past than j\n",
    "                orient Xi,lag(i) *-> Xj,lag(j)\n",
    "\n",
    "        i.e. edges always point from past -> future.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"Time orientation (past -> future: larger lag -> smaller lag)...\")\n",
    "        n = G.n_nodes\n",
    "        for i in range(n):\n",
    "            info_i = G.decode_node(i)\n",
    "            for j in range(n):\n",
    "                if not G.adj[i, j]:\n",
    "                    continue\n",
    "                info_j = G.decode_node(j)\n",
    "\n",
    "                # i earlier in time than j  <=>  lag(i) > lag(j)\n",
    "                if info_i.lag > info_j.lag:\n",
    "                    # orient i o-> j (circle at i, arrow at j), with homology\n",
    "                    if G.marks[i, j] == 0 and G.marks[j, i] == 0:\n",
    "                        G.orient_with_homology(i, j, 1, 0)\n",
    "\n",
    "\n",
    "    # --- line 10: v-structures with homology ---\n",
    "\n",
    "    def _orient_v_structures(self, G: DynamicPAG):\n",
    "        if self.verbose:\n",
    "            print(\"Orienting v-structures...\")\n",
    "        p = G.n_nodes\n",
    "        for k in range(p):\n",
    "            for i in range(p):\n",
    "                if i == k or not G.adj[i, k]:\n",
    "                    continue\n",
    "                for j in range(i + 1, p):\n",
    "                    if j == k or not G.adj[j, k]:\n",
    "                        continue\n",
    "                    if G.adj[i, j]:\n",
    "                        continue  # shielded\n",
    "                    S = G.get_sepset(i, j)\n",
    "                    if k not in S:\n",
    "                        # orient i *-> k <-* j\n",
    "                        G.orient_with_homology(i, k, 1, -1)\n",
    "                        G.orient_with_homology(j, k, 1, -1)\n",
    "\n",
    "    # --- line 11: second deletion using dynamic pds_s + homology ---\n",
    "\n",
    "    def _pds_deletion_phase(self, G: DynamicPAG, Z):\n",
    "        if self.verbose:\n",
    "            print(\"pds_s deletion phase with homology...\")\n",
    "        n = 0\n",
    "        p = G.n_nodes\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            if self.verbose:\n",
    "                print(f\"  pds_s, conditioning size n={n}\")\n",
    "            for i in range(p):\n",
    "                for j in range(i + 1, p):\n",
    "                    if not G.adj[i, j]:\n",
    "                        continue\n",
    "                    # candidate conditioning sets from pds_s\n",
    "                    P1 = pds_s(G, i, j)\n",
    "                    P2 = pds_s(G, j, i)\n",
    "                    P_union = list(P1.union(P2))\n",
    "                    if len(P_union) < n:\n",
    "                        continue\n",
    "                    found_sep = False\n",
    "                    for S in itertools.combinations(P_union, n):\n",
    "                        if self._indep(Z, i, j, S):\n",
    "                            if self.verbose:\n",
    "                                print(f\"    pds indep({G.node_label(i)}, {G.node_label(j)} | {len(S)} vars)\")\n",
    "                            G.delete_edge_with_homology(i, j)\n",
    "                            G.set_sepset(i, j, S)\n",
    "                            changed = True\n",
    "                            found_sep = True\n",
    "                            break\n",
    "                    if found_sep:\n",
    "                        continue\n",
    "            n += 1\n",
    "\n",
    "    # --- R1-R10 placeholder (needs full Zhang implementation) ---\n",
    "\n",
    "        # --- R1–R10 (Zhang 2008) orientation rules on DynamicPAG ---\n",
    "    # Assumptions:\n",
    "    # - G.marks[i,j] is mark at endpoint j on edge (i,j):\n",
    "    #       0  = circle (o)\n",
    "    #      -1  = tail   (-)\n",
    "    #       1  = arrow  (>)\n",
    "    # - G.adj[i,j] is True iff there is an edge between i and j.\n",
    "    # - G.orient_with_homology(i,j, mark_ij, mark_ji) orients (i,j) and\n",
    "    #   all homologous edges with endpoint marks mark_ij at j, mark_ji at i.\n",
    "    #\n",
    "    # We implement R1–R4 and R8–R10 exactly in Zhang (2008), restricted\n",
    "    # to MAGs without undirected edges (no selection bias), so R5–R7\n",
    "    # are omitted as per Zhang’s remark.\n",
    "\n",
    "    def _apply_R_rules(self, G: DynamicPAG):\n",
    "        n = G.n_nodes\n",
    "\n",
    "        def non_adjacent(a, b):\n",
    "            return not G.adj[a, b]\n",
    "\n",
    "        def is_arrow_into(child, parent):\n",
    "            # edge parent *-> child  ⇔ mark at child on (parent, child) is 1\n",
    "            return G.adj[parent, child] and G.marks[parent, child] == 1\n",
    "\n",
    "        def is_circle_at(i, j):\n",
    "            # circle at j on edge (i,j)\n",
    "            return G.adj[i, j] and G.marks[i, j] == 0\n",
    "\n",
    "        # --- R4 helpers: discriminating paths ---\n",
    "\n",
    "        def is_discriminating_path(path, V, X, Y):\n",
    "            \"\"\"\n",
    "            Check if 'path' (list of nodes [X,...,W,V,Y]) is a\n",
    "            discriminating path for V between X and Y, in the sense of\n",
    "            Zhang Def. 7 but adapted to the current PAG:\n",
    "            - length >= 3 edges (>= 4 nodes)\n",
    "            - V non-endpoint and adjacent to Y on path\n",
    "            - X not adjacent to Y\n",
    "            - every vertex between X and V is:\n",
    "                * a collider on the path\n",
    "                * a parent of Y (edge *-> Y).\n",
    "            \"\"\"\n",
    "            if len(path) < 4:\n",
    "                return False\n",
    "            if path[0] != X or path[-1] != Y:\n",
    "                return False\n",
    "            if V not in path[1:-1]:\n",
    "                return False\n",
    "            if not non_adjacent(X, Y):\n",
    "                return False\n",
    "\n",
    "            V_idx = path.index(V)\n",
    "            # V must be non-endpoint and directly before Y on the path\n",
    "            if V_idx == 0 or V_idx == len(path) - 1:\n",
    "                return False\n",
    "            if path[V_idx + 1] != Y:\n",
    "                return False\n",
    "\n",
    "            # Every vertex between X and V must be a collider on the path\n",
    "            # and must be a parent of Y (*-> Y).\n",
    "            for idx in range(1, V_idx):\n",
    "                v = path[idx]\n",
    "                prev_v = path[idx - 1]\n",
    "                next_v = path[idx + 1]\n",
    "                # collider on the path\n",
    "                if not G.is_collider(prev_v, v, next_v):\n",
    "                    return False\n",
    "                # parent of Y: edge v *-> Y  ⇒ mark at Y on (v,Y) is 1\n",
    "                if not is_arrow_into(Y, v):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        def all_simple_paths_unbounded(start, end):\n",
    "            \"\"\"\n",
    "            Generate all simple paths from start to end (no repeated nodes).\n",
    "            Use with care; graph is sparse after skeleton + pds, so it is\n",
    "            manageable for typical macro VAR sizes.\n",
    "            \"\"\"\n",
    "            stack = [(start, [start])]\n",
    "            while stack:\n",
    "                (v, path) = stack.pop()\n",
    "                for w in G.neighbors(v):\n",
    "                    if w in path:\n",
    "                        continue\n",
    "                    new_path = path + [w]\n",
    "                    if w == end:\n",
    "                        yield new_path\n",
    "                    else:\n",
    "                        stack.append((w, new_path))\n",
    "\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "\n",
    "            # ----------------- R1 -----------------\n",
    "            # R1: If α *-> β o--* γ and α,γ nonadjacent, then orient β o--* γ as β -> γ.\n",
    "            for beta in range(n):\n",
    "                for alpha in G.neighbors(beta):\n",
    "                    if not is_arrow_into(beta, alpha):\n",
    "                        continue  # need α *-> β\n",
    "                    for gamma in G.neighbors(beta):\n",
    "                        if gamma == alpha:\n",
    "                            continue\n",
    "                        # β o--* γ  -> circle at β on edge (β,γ)\n",
    "                        if not is_circle_at(beta, gamma):\n",
    "                            continue\n",
    "                        if not non_adjacent(alpha, gamma):\n",
    "                            continue\n",
    "                        # orient β -> γ  (tail at β, arrow at γ)\n",
    "                        if not (G.marks[beta, gamma] == 1 and G.marks[gamma, beta] == -1):\n",
    "                            G.orient_with_homology(beta, gamma, 1, -1)\n",
    "                            changed = True\n",
    "\n",
    "            # ----------------- R2 -----------------\n",
    "            # R2: If α -> β *-> γ (or α *-> β -> γ) and α *-◦ γ, orient α *-◦ γ as α *-> γ\n",
    "            for beta in range(n):\n",
    "                for alpha in G.neighbors(beta):\n",
    "                    for gamma in G.neighbors(beta):\n",
    "                        if gamma == alpha:\n",
    "                            continue\n",
    "                        # require β *-> γ and α *-> β (arrowheads into β and γ)\n",
    "                        if not (is_arrow_into(beta, alpha) and is_arrow_into(gamma, beta)):\n",
    "                            continue\n",
    "                        if not G.adj[alpha, gamma]:\n",
    "                            continue\n",
    "                        # α *-◦ γ  => circle at γ on (α,γ)\n",
    "                        if G.marks[gamma, alpha] != 0:\n",
    "                            continue\n",
    "                        # orient α o-> γ: arrow at γ, keep circle at α\n",
    "                        if not (G.marks[alpha, gamma] == 1 and G.marks[gamma, alpha] == 0):\n",
    "                            G.orient_with_homology(alpha, gamma, 1, 0)\n",
    "                            changed = True\n",
    "\n",
    "            # ----------------- R3 -----------------\n",
    "            # R3: If α *-> β <-* γ, α *-◦ θ ◦-* γ, α,γ nonadjacent,\n",
    "            #     and θ *-◦ β, then orient θ *-◦ β as θ *-> β.\n",
    "            for beta in range(n):\n",
    "                # collider α *-> β <-* γ\n",
    "                for alpha in G.neighbors(beta):\n",
    "                    if not is_arrow_into(beta, alpha):\n",
    "                        continue\n",
    "                    for gamma in G.neighbors(beta):\n",
    "                        if gamma == alpha:\n",
    "                            continue\n",
    "                        if not is_arrow_into(beta, gamma):\n",
    "                            continue\n",
    "                        if not non_adjacent(alpha, gamma):\n",
    "                            continue\n",
    "                        # search θ such that α *-◦ θ ◦-* γ and θ *-◦ β\n",
    "                        for theta in range(n):\n",
    "                            if theta in (alpha, beta, gamma):\n",
    "                                continue\n",
    "                            if not (G.adj[alpha, theta] and G.adj[theta, gamma] and G.adj[theta, beta]):\n",
    "                                continue\n",
    "                            # circles at θ on α-θ and γ-θ\n",
    "                            if G.marks[alpha, theta] != 0 or G.marks[gamma, theta] != 0:\n",
    "                                continue\n",
    "                            # circle at β on θ-β\n",
    "                            if G.marks[theta, beta] != 0:\n",
    "                                continue\n",
    "                            # orient θ o-> β: arrow at β, circle at θ\n",
    "                            if not (G.marks[theta, beta] == 1 and G.marks[beta, theta] == 0):\n",
    "                                G.orient_with_homology(theta, beta, 1, 0)\n",
    "                                changed = True\n",
    "\n",
    "            # ----------------- R4 -----------------\n",
    "            # R4: If u = <θ,...,α,β,γ> is a discriminating path between θ and γ for β,\n",
    "            #     and β o--* γ, then:\n",
    "            #     - if β ∈ Sepset(θ,γ), orient β o--* γ as β -> γ\n",
    "            #     - else orient <α,β,γ> as α <-> β <-> γ.\n",
    "            for beta in range(n):\n",
    "                for theta in range(n):\n",
    "                    if theta == beta:\n",
    "                        continue\n",
    "                    for gamma in range(n):\n",
    "                        if gamma in (theta, beta):\n",
    "                            continue\n",
    "                        if not G.adj[beta, gamma]:\n",
    "                            continue\n",
    "                        # β o--* γ : circle at β on edge (β,γ)\n",
    "                        if G.marks[beta, gamma] != 0:\n",
    "                            continue\n",
    "                        # search discriminating paths θ ... β γ\n",
    "                        for path in all_simple_paths_unbounded(theta, gamma):\n",
    "                            if beta not in path:\n",
    "                                continue\n",
    "                            if not is_discriminating_path(path, beta, theta, gamma):\n",
    "                                continue\n",
    "                            # found discriminating path\n",
    "                            sepset = G.get_sepset(theta, gamma)\n",
    "                            if beta in sepset:\n",
    "                                # β -> γ\n",
    "                                if not (G.marks[beta, gamma] == 1 and G.marks[gamma, beta] == -1):\n",
    "                                    G.orient_with_homology(beta, gamma, 1, -1)\n",
    "                                    changed = True\n",
    "                            else:\n",
    "                                # α <-> β <-> γ, where α is predecessor of β on path\n",
    "                                b_idx = path.index(beta)\n",
    "                                if b_idx == 0:\n",
    "                                    continue\n",
    "                                alpha = path[b_idx - 1]\n",
    "                                # α <-> β\n",
    "                                if not (G.marks[alpha, beta] == 1 and G.marks[beta, alpha] == 1):\n",
    "                                    G.orient_with_homology(alpha, beta, 1, 1)\n",
    "                                    changed = True\n",
    "                                # β <-> γ\n",
    "                                if not (G.marks[beta, gamma] == 1 and G.marks[gamma, beta] == 1):\n",
    "                                    G.orient_with_homology(beta, gamma, 1, 1)\n",
    "                                    changed = True\n",
    "                            break  # only need one discriminating path\n",
    "\n",
    "            # ----------------- R5 -----------------\n",
    "            # If α - β (undirected) and exists γ -> α with γ not adjacent to β,\n",
    "            # orient β *-> α (arrowhead at α).\n",
    "            for alpha in range(n):\n",
    "                for beta in range(n):\n",
    "                    if alpha == beta:\n",
    "                        continue\n",
    "                    # alpha — beta   (both tails)\n",
    "                    if not (G.adj[alpha, beta] and \n",
    "                            G.marks[alpha, beta] == -1 and \n",
    "                            G.marks[beta, alpha] == -1):\n",
    "                        continue\n",
    "                    for gamma in range(n):\n",
    "                        if gamma in (alpha, beta):\n",
    "                            continue\n",
    "                        # γ -> α  (arrowhead at α)\n",
    "                        if not (G.adj[gamma, alpha] and G.marks[gamma, alpha] == 1):\n",
    "                            continue\n",
    "                        # γ not adjacent to β\n",
    "                        if G.adj[gamma, beta]:\n",
    "                            continue\n",
    "                        # orient β *-> α : tail at β, arrow at α\n",
    "                        if not (G.marks[beta, alpha] == 1 and G.marks[alpha, beta] == -1):\n",
    "                            G.orient_with_homology(beta, alpha, 1, -1)\n",
    "                            changed = True\n",
    "                            break\n",
    "                        # ----------------- R6 -----------------\n",
    "            # If α - β and there exists a discriminating path for α between\n",
    "            # some γ and β, orient β *-> α.\n",
    "            for alpha in range(n):\n",
    "                for beta in range(n):\n",
    "                    if alpha == beta:\n",
    "                        continue\n",
    "                    # α — β\n",
    "                    if not (G.adj[alpha, beta] and \n",
    "                            G.marks[alpha, beta] == -1 and \n",
    "                            G.marks[beta, alpha] == -1):\n",
    "                        continue\n",
    "\n",
    "                    # search discriminating paths <γ, ..., α, β>\n",
    "                    for gamma in range(n):\n",
    "                        if gamma in (alpha, beta):\n",
    "                            continue\n",
    "\n",
    "                        for path in all_simple_paths_unbounded(gamma, beta):\n",
    "                            # path must end with ..., α, β\n",
    "                            if len(path) < 3:\n",
    "                                continue\n",
    "                            if path[-2] != alpha:\n",
    "                                continue\n",
    "\n",
    "                            if is_discriminating_path(path, alpha, gamma, beta):\n",
    "                                # orient β *-> α\n",
    "                                if not (G.marks[beta, alpha] == 1 and G.marks[alpha, beta] == -1):\n",
    "                                    G.orient_with_homology(beta, alpha, 1, -1)\n",
    "                                    changed = True\n",
    "                                break\n",
    "                        if changed:\n",
    "                            break\n",
    "                        # ----------------- R7 -----------------\n",
    "            # If α — β cannot be oriented by R5 or R6 but remains undirected,\n",
    "            # orient α <-> β (bidirected).\n",
    "            for alpha in range(n):\n",
    "                for beta in range(n):\n",
    "                    if alpha == beta:\n",
    "                        continue\n",
    "                    # still undirected?\n",
    "                    if not (G.adj[alpha, beta] and \n",
    "                            G.marks[alpha, beta] == -1 and \n",
    "                            G.marks[beta, alpha] == -1):\n",
    "                        continue\n",
    "                    # convert to bidirected α <-> β\n",
    "                    G.orient_with_homology(alpha, beta, 1, 1)\n",
    "                    changed = True\n",
    "            \n",
    "\n",
    "            # ----------------- R8 -----------------\n",
    "            # R8: If α -> β -> γ or α -◦ β -> γ, and α ◦-> γ,\n",
    "            #     orient α ◦-> γ as α -> γ.\n",
    "            for alpha in range(n):\n",
    "                for beta in G.neighbors(alpha):\n",
    "                    for gamma in G.neighbors(beta):\n",
    "                        if gamma == alpha:\n",
    "                            continue\n",
    "                        # β -> γ\n",
    "                        if not is_arrow_into(gamma, beta):\n",
    "                            continue\n",
    "                        # either α -> β or α -◦ β\n",
    "                        cond1 = is_arrow_into(beta, alpha)  # α *-> β\n",
    "                        cond2 = (G.adj[alpha, beta] and\n",
    "                                 G.marks[alpha, beta] == 0 and  # circle at β\n",
    "                                 G.marks[beta, alpha] == -1)   # tail at α\n",
    "                        if not (cond1 or cond2):\n",
    "                            continue\n",
    "                        # α ◦-> γ : circle at α, arrow at γ\n",
    "                        if not (G.adj[alpha, gamma] and\n",
    "                                G.marks[alpha, gamma] == 1 and\n",
    "                                G.marks[gamma, alpha] == 0):\n",
    "                            continue\n",
    "                        # orient α -> γ: tail at α, arrow at γ\n",
    "                        if not (G.marks[alpha, gamma] == 1 and G.marks[gamma, alpha] == -1):\n",
    "                            G.orient_with_homology(alpha, gamma, 1, -1)\n",
    "                            changed = True\n",
    "\n",
    "            # -------- helpers for R9–R10: uncovered p.d. paths ----------\n",
    "\n",
    "            def is_uncovered(path):\n",
    "                # every consecutive triple unshielded: Vi-1 and Vi+1 nonadjacent\n",
    "                if len(path) < 3:\n",
    "                    return True\n",
    "                for i in range(1, len(path) - 1):\n",
    "                    if G.adj[path[i - 1], path[i + 1]]:\n",
    "                        return False\n",
    "                return True\n",
    "\n",
    "            def is_pd_edge(u, v):\n",
    "                # edge u ?-? v is potentially directed from u to v\n",
    "                # if there's no arrowhead into u along u->v\n",
    "                return G.adj[u, v] and (G.marks[v, u] != 1)\n",
    "\n",
    "            def uncovered_pd_paths(start, end):\n",
    "                stack = [(start, [start])]\n",
    "                while stack:\n",
    "                    (v, path) = stack.pop()\n",
    "                    for w in G.neighbors(v):\n",
    "                        if w in path:\n",
    "                            continue\n",
    "                        if not is_pd_edge(v, w):\n",
    "                            continue\n",
    "                        new_path = path + [w]\n",
    "                        if not is_uncovered(new_path):\n",
    "                            continue\n",
    "                        if w == end:\n",
    "                            yield new_path\n",
    "                        else:\n",
    "                            stack.append((w, new_path))\n",
    "\n",
    "            # ----------------- R9 -----------------\n",
    "            # R9: If α ◦-> γ, and there is an uncovered p.d. path\n",
    "            #     p = <α, β, θ, ..., γ> from α to γ such that β and γ\n",
    "            #     are not adjacent, then orient α ◦-> γ as α -> γ.\n",
    "            for alpha in range(n):\n",
    "                for gamma in range(n):\n",
    "                    if gamma == alpha:\n",
    "                        continue\n",
    "                    # α ◦-> γ\n",
    "                    if not (G.adj[alpha, gamma] and\n",
    "                            G.marks[alpha, gamma] == 1 and\n",
    "                            G.marks[gamma, alpha] == 0):\n",
    "                        continue\n",
    "                    for path in uncovered_pd_paths(alpha, gamma):\n",
    "                        if len(path) < 3:\n",
    "                            continue\n",
    "                        beta = path[1]\n",
    "                        if not non_adjacent(beta, gamma):\n",
    "                            continue\n",
    "                        # orient α -> γ\n",
    "                        if not (G.marks[alpha, gamma] == 1 and G.marks[gamma, alpha] == -1):\n",
    "                            G.orient_with_homology(alpha, gamma, 1, -1)\n",
    "                            changed = True\n",
    "                        break  # one path is enough\n",
    "\n",
    "            # ----------------- R10 -----------------\n",
    "            # R10: Suppose α ◦-> γ, β -> γ <- θ,\n",
    "            #       p1 is uncovered p.d. path α ... β,\n",
    "            #       p2 is uncovered p.d. path α ... θ,\n",
    "            #       let μ be neighbor of α on p1, ω neighbor of α on p2,\n",
    "            #       if μ ≠ ω and μ,ω nonadjacent, orient α ◦-> γ as α -> γ.\n",
    "            for alpha in range(n):\n",
    "                for gamma in range(n):\n",
    "                    if gamma == alpha:\n",
    "                        continue\n",
    "                    # α ◦-> γ\n",
    "                    if not (G.adj[alpha, gamma] and\n",
    "                            G.marks[alpha, gamma] == 1 and\n",
    "                            G.marks[gamma, alpha] == 0):\n",
    "                        continue\n",
    "                    # nodes β, θ with β -> γ <- θ\n",
    "                    parents = [v for v in range(n) if is_arrow_into(gamma, v)]\n",
    "                    for beta in parents:\n",
    "                        for theta in parents:\n",
    "                            if theta == beta or theta == alpha or beta == alpha:\n",
    "                                continue\n",
    "                            # p1: uncovered p.d. from α to β\n",
    "                            p1_list = list(uncovered_pd_paths(alpha, beta))\n",
    "                            if not p1_list:\n",
    "                                continue\n",
    "                            # p2: uncovered p.d. from α to θ\n",
    "                            p2_list = list(uncovered_pd_paths(alpha, theta))\n",
    "                            if not p2_list:\n",
    "                                continue\n",
    "                            # take first such paths\n",
    "                            p1 = p1_list[0]\n",
    "                            p2 = p2_list[0]\n",
    "                            if len(p1) < 2 or len(p2) < 2:\n",
    "                                continue\n",
    "                            mu = p1[1]\n",
    "                            omega = p2[1]\n",
    "                            if mu == omega:\n",
    "                                continue\n",
    "                            if not non_adjacent(mu, omega):\n",
    "                                continue\n",
    "                            # orient α -> γ\n",
    "                            if not (G.marks[alpha, gamma] == 1 and G.marks[gamma, alpha] == -1):\n",
    "                                G.orient_with_homology(alpha, gamma, 1, -1)\n",
    "                                changed = True\n",
    "                            break  # β,θ found that trigger R10\n",
    "                        if changed:\n",
    "                            break\n",
    "                    # end loops over beta, theta\n",
    "        # end while changed\n",
    "\n",
    "\n",
    "    # --- main entry point ---\n",
    "\n",
    "    def fit(self, X, var_names=None):\n",
    "        \"\"\"\n",
    "        X: numpy array (T, k)\n",
    "        var_names: list of length k\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        T, k = X.shape\n",
    "        if var_names is None:\n",
    "            var_names = [f\"X{i}\" for i in range(k)]\n",
    "        self.var_names_ = var_names\n",
    "\n",
    "        # build lagged matrix\n",
    "        Z, lagged_names = self._build_lagged_matrix(X, var_names)\n",
    "        self.Z_ = Z\n",
    "\n",
    "        # init dynamic PAG\n",
    "        G = DynamicPAG(lagged_names, self.max_lag)\n",
    "\n",
    "        assert G.n_nodes == Z.shape[1], (\n",
    "        f\"ERROR: Graph has {G.n_nodes} nodes but Z has {Z.shape[1]} columns. \"\n",
    "        f\"Check R5–R7 indentation and DynamicPAG construction.\")\n",
    "\n",
    "        # Algorithm 3.1 steps\n",
    "        # 1–2: done via initialization\n",
    "        # 3–8: skeleton\n",
    "        self._skeleton_phase(G, Z)\n",
    "\n",
    "        # 9: time orientation\n",
    "        self._time_orientation(G)\n",
    "\n",
    "        # 10: v-structures\n",
    "        self._orient_v_structures(G)\n",
    "\n",
    "        # 11: pds_s deletion\n",
    "        self._pds_deletion_phase(G, Z)\n",
    "\n",
    "        # 12: reset o-o and repeat 9–10\n",
    "        G.reset_all_to_oo()\n",
    "        self._time_orientation(G)\n",
    "        self._orient_v_structures(G)\n",
    "\n",
    "        # 13: R1–R10\n",
    "        self._apply_R_rules(G)\n",
    "\n",
    "        self.graph_ = G\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ceaaf19-5961-47d7-93c6-85771cff7085",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to determine R_HOME.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 5. ICF/BIC scoring via R ggm\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mro\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy2ri\n\u001b[1;32m      7\u001b[0m numpy2ri\u001b[38;5;241m.\u001b[39mactivate()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/rpy2/robjects/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrinterface_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenrlib\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrlike\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrlc\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobject\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RObjectMixin, RObject\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Environment,\n\u001b[1;32m     25\u001b[0m                                         local_context)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/rpy2/robjects/robject.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrinterface_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m conversion\n\u001b[0;32m---> 11\u001b[0m rpy2\u001b[38;5;241m.\u001b[39mrinterface\u001b[38;5;241m.\u001b[39minitr()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_add_warn_reticulate_hook\u001b[39m():\n\u001b[1;32m     15\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m    WARNING: The R package \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreticulate\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m only fixed recently\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m    an issue that caused a segfault when used with rpy2:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m    the fix.\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/rpy2/rinterface/__init__.py:1130\u001b[0m, in \u001b[0;36minitr\u001b[0;34m(interactive, _want_setcallbacks, _c_stack_limit)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR is already initialized. No need to initialize.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1130\u001b[0m _setrenvvars(_ENVVAR_ACTION_MAP)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mis_r_externally_initialized():\n\u001b[1;32m   1132\u001b[0m     embedded\u001b[38;5;241m.\u001b[39m_setinitialized()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/rpy2/rinterface/__init__.py:1222\u001b[0m, in \u001b[0;36m_setrenvvars\u001b[0;34m(action_map)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_setrenvvars\u001b[39m(action_map: typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, _ENVVAR_ACTION]):\n\u001b[1;32m   1221\u001b[0m     new_envvars \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _getrenvvars():\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m   1224\u001b[0m             action \u001b[38;5;241m=\u001b[39m action_map[k]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/rpy2/rinterface/__init__.py:1175\u001b[0m, in \u001b[0;36m_getrenvvars\u001b[0;34m(baselinevars, r_home)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     r_home \u001b[38;5;241m=\u001b[39m openrlib\u001b[38;5;241m.\u001b[39mR_HOME\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r_home \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to determine R_HOME.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;66;03m# Use a temporary file to write the environment variables. Windows\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;66;03m# has a file locking system that requires a slightly more complicated\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;66;03m# implementation than it would otherwise be on other OSes.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m temp_fh \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to determine R_HOME."
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 5. ICF/BIC scoring via R ggm\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import numpy2ri\n",
    "numpy2ri.activate()\n",
    "\n",
    "# load ggm + helper once\n",
    "ro.r('library(ggm)')\n",
    "ro.r(\"\"\"\n",
    "icf_bic <- function(S, amat, n) {\n",
    "  A <- AG(amat, showmat=FALSE)\n",
    "  fit <- fitAncestralGraph(S, A, n.obs=n)\n",
    "  return(list(\n",
    "    loglik = fit$loglik,\n",
    "    df     = fit$df,\n",
    "    bic    = -2*fit$loglik + fit$df * log(n)\n",
    "  ))\n",
    "}\n",
    "\"\"\")\n",
    "icf_bic_R = ro.r[\"icf_bic\"]\n",
    "\n",
    "\n",
    "def pag_to_mag(self, G):\n",
    "    \"\"\"\n",
    "    Convert a PAG into a single valid MAG consistent with:\n",
    "    - all invariant arrowheads\n",
    "    - all invariant tails\n",
    "    - ancestral graph constraints\n",
    "    - minimal additional orientation\n",
    "    \n",
    "    Returns an adjacency matrix with codes:\n",
    "      0 = no edge\n",
    "      1 = i -> j   (directed)\n",
    "      2 = i <-> j  (bidirected / latent confounding)\n",
    "      3 = i - j    (undirected adjacency)\n",
    "    \"\"\"\n",
    "\n",
    "    p = G.num_nodes\n",
    "    amat = np.zeros((p, p), dtype=int)\n",
    "\n",
    "    def has_arrowhead(i, j):\n",
    "        return G.marks[i, j] == 1     # arrowhead at j\n",
    "\n",
    "    def has_tail(i, j):\n",
    "        return G.marks[i, j] == -1    # tail at j (i *- j)\n",
    "\n",
    "    for i in range(p):\n",
    "        for j in range(i + 1, p):\n",
    "            if not G.adj[i, j]:\n",
    "                continue\n",
    "\n",
    "            # Case 1: Fully oriented edges\n",
    "            if has_tail(i, j) and has_arrowhead(j, i):\n",
    "                # i *-> j\n",
    "                amat[i, j] = 1  # i->j\n",
    "                continue\n",
    "            if has_tail(j, i) and has_arrowhead(i, j):\n",
    "                # j *-> i\n",
    "                amat[j, i] = 1\n",
    "                continue\n",
    "\n",
    "            # Case 2: Invariant arrowheads (one-ended orientation)\n",
    "            if has_arrowhead(i, j) and not has_arrowhead(j, i):\n",
    "                # i *--> j means j is not ancestor of i, so orient i <- j\n",
    "                amat[j, i] = 1\n",
    "                continue\n",
    "            if has_arrowhead(j, i) and not has_arrowhead(i, j):\n",
    "                amat[i, j] = 1\n",
    "                continue\n",
    "\n",
    "            # Case 3: Bidirected (latent confounding)\n",
    "            # PAG: o-> or <-o or o-o could hide latent confounding.\n",
    "            # If both endpoints uncertain (circles), assign <-> as safe.\n",
    "            if G.marks[i, j] == 0 and G.marks[j, i] == 0:\n",
    "                amat[i, j] = amat[j, i] = 2   # i <-> j\n",
    "                continue\n",
    "\n",
    "            # Case 4: Undirected edge ambiguous endpoints (tail-circle)\n",
    "            # Use undirected as minimal encoding.\n",
    "            amat[i, j] = amat[j, i] = 3\n",
    "\n",
    "    return amat\n",
    "\n",
    "\n",
    "\n",
    "def icf_bic_score(Z, G: DynamicPAG):\n",
    "    \"\"\"\n",
    "    Compute ICF/BIC for one SVAR-FCI PAG.\n",
    "    Z: lagged data (n, p_nodes)  (same Z used in SVAR_FCI)\n",
    "    G: DynamicPAG\n",
    "    \"\"\"\n",
    "    n = Z.shape[0]\n",
    "    S = np.cov(Z, rowvar=False)\n",
    "    amat = pag_to_mag(G)\n",
    "    res = icf_bic_R(S, amat, n)\n",
    "    return {\n",
    "        \"loglik\": float(res[0][0]),\n",
    "        \"df\": float(res[1][0]),\n",
    "        \"bic\": float(res[2][0]),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa677378-cd21-4e28-9b83-790c67c01f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 6. Data-driven selection of alpha and p (Appendix)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def select_alpha(\n",
    "    X,\n",
    "    var_names,\n",
    "    p,\n",
    "    alpha_grid=np.arange(0.01, 0.41, 0.01),\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    For fixed maximum lag p, choose alpha maximizing BIC(P_hat_alpha).\n",
    "    \"\"\"\n",
    "    best_alpha = None\n",
    "    best_bic = np.inf\n",
    "    best_model = None\n",
    "    best_score = None\n",
    "\n",
    "    for alpha in alpha_grid:\n",
    "        if verbose:\n",
    "            print(f\"alpha={alpha:.3f}\")\n",
    "        model = SVAR_FCI(alpha=alpha, max_lag=p, verbose=False)\n",
    "        model.fit(X, var_names=var_names)\n",
    "        score = icf_bic_score(model.Z_, model.graph_)\n",
    "        if verbose:\n",
    "            print(\"  BIC:\", score[\"bic\"])\n",
    "        if score[\"bic\"] < best_bic:\n",
    "            best_bic = score[\"bic\"]\n",
    "            best_alpha = alpha\n",
    "            best_model = model\n",
    "            best_score = score\n",
    "\n",
    "    return best_model, best_alpha, best_score\n",
    "\n",
    "\n",
    "def select_p(\n",
    "    X,\n",
    "    var_names,\n",
    "    alpha,\n",
    "    p_grid,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    For fixed alpha, choose p maximizing BIC(P_hat_p).\n",
    "    \"\"\"\n",
    "    best_p = None\n",
    "    best_bic = np.inf\n",
    "    best_model = None\n",
    "    best_score = None\n",
    "\n",
    "    for p in p_grid:\n",
    "        if verbose:\n",
    "            print(f\"p={p}\")\n",
    "        model = SVAR_FCI(alpha=alpha, max_lag=p, verbose=False)\n",
    "        model.fit(X, var_names=var_names)\n",
    "        score = icf_bic_score(model.Z_, model.graph_)\n",
    "        if verbose:\n",
    "            print(\"  BIC:\", score[\"bic\"])\n",
    "        if score[\"bic\"] < best_bic:\n",
    "            best_bic = score[\"bic\"]\n",
    "            best_p = p\n",
    "            best_model = model\n",
    "            best_score = score\n",
    "\n",
    "    return best_model, best_p, best_score\n",
    "\n",
    "\n",
    "def select_alpha_and_p(\n",
    "    X,\n",
    "    var_names,\n",
    "    alpha_grid=np.arange(0.01, 0.41, 0.01),\n",
    "    p_grid=range(1, 5),\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Joint search over alpha and p as described in the appendix.\n",
    "    \"\"\"\n",
    "    best_alpha = None\n",
    "    best_p = None\n",
    "    best_bic = np.inf\n",
    "    best_model = None\n",
    "    best_score = None\n",
    "\n",
    "    for alpha in alpha_grid:\n",
    "        for p in p_grid:\n",
    "            if verbose:\n",
    "                print(f\"alpha={alpha:.3f}, p={p}\")\n",
    "            model = SVAR_FCI(alpha=alpha, max_lag=p, verbose=False)\n",
    "            model.fit(X, var_names=var_names)\n",
    "            score = icf_bic_score(model.Z_, model.graph_)\n",
    "            if verbose:\n",
    "                print(\"  BIC:\", score[\"bic\"])\n",
    "            if score[\"bic\"] < best_bic:\n",
    "                best_bic = score[\"bic\"]\n",
    "                best_alpha = alpha\n",
    "                best_p = p\n",
    "                best_model = model\n",
    "                best_score = score\n",
    "\n",
    "    return best_model, best_alpha, best_p, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9df0e8-becc-41db-b326-b9633ea8e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def simulate_svar_data(T=1000, seed=0):\n",
    "    \"\"\"\n",
    "    Simulate 3-var VAR(2) with known causal DAG:\n",
    "        X_{t-1} → Y_t\n",
    "        Y_{t-1} → Z_t\n",
    "        Z_{t-1} → X_t\n",
    "    plus latent confounding:  X_t ↔ Z_t\n",
    "\n",
    "    Returns:\n",
    "        X : (T,3) matrix\n",
    "        var_names : [\"X\",\"Y\",\"Z\"]\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    A1 = np.array([\n",
    "        [0.0, 0.0, 0.4],   # Z_{t-1} → X_t\n",
    "        [0.3, 0.0, 0.0],   # X_{t-1} → Y_t\n",
    "        [0.0, 0.2, 0.0]    # Y_{t-1} → Z_t\n",
    "    ])\n",
    "    A2 = np.zeros((3,3))   # no second lag effect, but keeps structure simple\n",
    "\n",
    "    # latent confounding: U influences X_t and Z_t\n",
    "    T = T + 5\n",
    "    X = np.zeros((T,3))\n",
    "    for t in range(2, T):\n",
    "        eta = rng.normal(size=3)\n",
    "        latent = rng.normal()\n",
    "\n",
    "        X[t] = (\n",
    "            A1 @ X[t-1]\n",
    "            + A2 @ X[t-2]\n",
    "            + eta\n",
    "            + np.array([latent, 0, latent]) * 0.5\n",
    "        )\n",
    "\n",
    "    return X[5:], [\"X\",\"Y\",\"Z\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7ef64-f452-4113-9097-8ebed8005bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_svar_fci_once():\n",
    "    X, names = simulate_svar_data(T=1200, seed=42)\n",
    "    model = SVAR_FCI(alpha=0.05, max_lag=2, verbose=True)\n",
    "    model.fit(X, var_names=names)\n",
    "\n",
    "    G = model.graph_\n",
    "    print(\"\\n=== Learned PAG marks ===\")\n",
    "    print(G.marks)\n",
    "    print(\"\\n=== Learned adjacency ===\")\n",
    "    print(G.adj.astype(int))\n",
    "\n",
    "    # Test MAP→MAG conversion\n",
    "    amat = pag_to_mag(model, G)\n",
    "    print(\"\\n=== Converted MAG adjacency ===\")\n",
    "    print(amat)\n",
    "\n",
    "    return model, amat\n",
    "\n",
    "model, amat = test_svar_fci_once()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6956bdc-50ff-4c94-9145-566051ba83df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
